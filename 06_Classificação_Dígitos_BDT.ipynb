{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/UERJ-FISICA/ML4PPGF_UERJ/blob/PPGF-2022-1/06_Classifica%C3%A7%C3%A3o_D%C3%ADgitos_BDT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eth4gcAwUHag",
    "outputId": "b5e394da-70f0-4ac8-e80b-32ae18b92474"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import dump, load\n",
    "\n",
    "import sklearn\n",
    "print ( sklearn.__version__ )\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "65OPlsvOT8qN"
   },
   "outputs": [],
   "source": [
    "train_model = True\n",
    "run_grid_search = True\n",
    "save_model = True\n",
    "\n",
    "model_path = \"\"\n",
    "scaler_path = \"\"\n",
    "if not train_model:\n",
    "#     model_path = \"ada_clf.joblib\"\n",
    "    model_path = \"models/BDT/ada_clf.joblib\"\n",
    "#     scaler_path = \"standard_scaler.joblib\"\n",
    "    scaler_path = \"models/BDT/standard_scaler.joblib\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Azo22KMNU4Uw"
   },
   "source": [
    "### Amostra de dígitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ndOpxbMNUILQ",
    "outputId": "12e27bda-f660-43a8-e038-8799929ed35e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "def sort_by_target(mnist):\n",
    "    reorder_train = np.array(sorted([(target, i) for i, target in enumerate(mnist.target[:60000])]))[:, 1]\n",
    "    reorder_test = np.array(sorted([(target, i) for i, target in enumerate(mnist.target[60000:])]))[:, 1]\n",
    "    mnist.data[:60000] = mnist.data[reorder_train]\n",
    "    mnist.target[:60000] = mnist.target[reorder_train]\n",
    "    mnist.data[60000:] = mnist.data[reorder_test + 60000]\n",
    "    mnist.target[60000:] = mnist.target[reorder_test + 60000]\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True, as_frame=False)\n",
    "mnist.target = mnist.target.astype(np.int8)\n",
    "sort_by_target(mnist)\n",
    "X_train_raw = mnist.data[:60000]\n",
    "y_train = mnist.target[:60000]\n",
    "X_test_raw = mnist.data[60000:]\n",
    "y_test = mnist.target[60000:]\n",
    "\n",
    "print ( X_train_raw.shape )\n",
    "print ( X_test_raw.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vEsO3RNVIEV"
   },
   "source": [
    "### Renormalização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FcKdUJSkVG7d",
    "outputId": "80776d9f-7d70-430e-f675-0ea90bfd6dbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler()\n",
      "3\n",
      "[ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      " -0.00441808 -0.00575482 -0.00408252 -0.00408252  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.         -0.00408252 -0.00470969 -0.00879935 -0.01159056\n",
      " -0.01475898 -0.01928485 -0.0246718  -0.02907103 -0.03059266 -0.03116401\n",
      " -0.03196287 -0.03020254 -0.03131022 -0.0283834  -0.02311919 -0.01916663\n",
      " -0.0167723  -0.01099636 -0.00832486 -0.00438069  0.          0.\n",
      "  0.          0.          0.          0.         -0.00408252 -0.00539535\n",
      " -0.00852241 -0.01198504 -0.01765348 -0.0277109  -0.03702009 -0.05215128\n",
      " -0.0670362  -0.08301705 -0.0993793  -0.11518413 -0.12913326 -0.13839468\n",
      " -0.13888363 -0.13184344 -0.12042952 -0.10189079 -0.0786049  -0.05699561\n",
      " -0.03965768 -0.02372839 -0.01408835 -0.00783084  0.          0.\n",
      "  0.          0.         -0.00536838 -0.00887061 -0.01407082 -0.02214681\n",
      " -0.03518014 -0.05502368 -0.07909613 -0.10764901 -0.13716994 -0.16710576\n",
      " -0.19600876 -0.22449111 -0.24865599 -0.26211797 -0.2625969  -0.2478559\n",
      " -0.221947   -0.1872114  -0.14764013 -0.10816436 -0.07681211 -0.0470753\n",
      " -0.03020197 -0.01524124 -0.00528372  0.          0.         -0.00408252\n",
      " -0.00776342 -0.01489325 -0.02396275 -0.0503409  -0.07876747 -0.11618154\n",
      " -0.16124756 -0.21196164 -0.26689873 -0.32567801 -0.39024155 -0.45207638\n",
      " -0.49939798 -0.52342832 -0.51761889 -0.48090242 -0.42307969 -0.35674039\n",
      " -0.28368365 -0.21683666 -0.15852438 -0.10878458 -0.07092253 -0.03895348\n",
      " -0.01425239 -0.0057705   0.          0.         -0.01190174 -0.02205016\n",
      " -0.05183807 -0.0906597  -0.13966711 -0.19708212 -0.26438473 -0.34073044\n",
      " -0.39570842  0.56889228  0.75400463  0.5548641   0.7362153   1.18345211\n",
      "  0.02851033 -0.74381141 -0.6665595  -0.5562504  -0.44764565 -0.34762461\n",
      " -0.26084091 -0.19030605 -0.13108013 -0.07484604 -0.03193013 -0.00820892\n",
      "  0.         -0.00557015 -0.01566193 -0.03636566 -0.07902431 -0.13328909\n",
      " -0.19915441 -0.27542969 -0.36333595 -0.43824283  0.68057305  1.80421592\n",
      "  1.52911309  1.33100961  1.20791723  1.10297085  1.17766993 -0.5263741\n",
      " -0.85654422 -0.72455973 -0.5806059  -0.45215876 -0.33932343 -0.24893037\n",
      " -0.1729397  -0.10410424 -0.04831762 -0.01470802 -0.00408252 -0.01323101\n",
      " -0.02624382 -0.05915859 -0.11300485 -0.17844153 -0.25800481 -0.35091181\n",
      " -0.45909822 -0.07476434  1.7713391   1.48785793  1.1770651   0.17209049\n",
      "  0.66322629 -0.08534834  1.09468453  1.1504372  -0.68973271 -0.86295358\n",
      " -0.69048024 -0.53290132 -0.39754744 -0.28768128 -0.19700703 -0.12122894\n",
      " -0.05680861 -0.01539067 -0.00502549 -0.01732052 -0.04308054 -0.0852489\n",
      " -0.13945837 -0.21088331 -0.30001798 -0.40728153  0.51176491  1.4779733\n",
      "  1.37741778  0.32173482 -0.79593524 -1.10798073 -1.10659099 -0.42725732\n",
      "  1.18512413  1.11562325 -0.7475138  -0.9129785  -0.73919131 -0.5710055\n",
      " -0.423671   -0.29819621 -0.19768614 -0.12068382 -0.05393563 -0.01350554\n",
      " -0.00590571 -0.02110967 -0.05298904 -0.09307849 -0.15039873 -0.22619102\n",
      " -0.32364534 -0.44213122  0.87901738  1.21535913 -0.59132495 -0.99238771\n",
      " -0.99508845 -0.9495566  -0.90890463 -0.07713623  1.36895746 -0.17986192\n",
      " -0.99948655 -0.90150861 -0.73668152 -0.56758942 -0.4201719  -0.2901746\n",
      " -0.18148235 -0.10493977 -0.04721317 -0.01413087 -0.00577281 -0.02263228\n",
      " -0.05280317 -0.09220581 -0.1474517  -0.22728459 -0.33242832 -0.46269616\n",
      " -0.61903352 -0.78428269 -0.90820988 -0.93137298 -0.86957693 -0.79705953\n",
      " -0.66457213  1.17384856  1.38844969 -0.61442017 -0.96213107 -0.86347326\n",
      " -0.70132425 -0.53739656 -0.39677103 -0.27122264 -0.15932446 -0.08125841\n",
      " -0.03695087 -0.0118734  -0.00705517 -0.02077118 -0.04720356 -0.08200384\n",
      " -0.13745728 -0.22518196 -0.33849238 -0.482935   -0.64828822 -0.80980531\n",
      " -0.89646046 -0.87178559 -0.7849761  -0.73254174  0.72839656  1.58304148\n",
      "  0.83099431 -0.90495036 -0.95554794 -0.8249029  -0.65598784 -0.49936419\n",
      " -0.36957331 -0.25846441 -0.14969571 -0.06111136 -0.02801157 -0.0091251\n",
      " -0.00530435 -0.0162384  -0.03637861 -0.06858201 -0.1273685  -0.22614336\n",
      " -0.35220291 -0.50758351 -0.67944964 -0.82825105 -0.88883004 -0.74946836\n",
      " -0.0164137   0.91830626  1.33752039  1.37394227  1.28331827  0.6337995\n",
      " -0.35441237 -0.73807682 -0.61674936 -0.47007288 -0.35512441 -0.25540754\n",
      " -0.15382451 -0.05245428 -0.02150587 -0.00992198 -0.00408252 -0.01093439\n",
      " -0.0255448  -0.05707308 -0.12466202 -0.23849817 -0.3732589  -0.53313607\n",
      " -0.70209414 -0.83745005 -0.34415486  0.95922572  1.57150594  1.44443531\n",
      "  1.25317927  0.7708198   0.62024012  1.05574835  1.30094213  1.03008063\n",
      " -0.41146003 -0.46091024 -0.35550055 -0.26354918 -0.16450369 -0.05951303\n",
      " -0.02336867 -0.00740432 -0.00408252 -0.00798835 -0.01829645 -0.05133943\n",
      " -0.1293464  -0.25752139 -0.39501133 -0.55042172 -0.70732309 -0.82604982\n",
      "  0.39179698  1.48283375  1.03657078 -0.12928103 -0.54751414 -1.13724891\n",
      " -1.24819354 -0.63255879  0.26113957  1.67313264  0.63754293 -0.47201999\n",
      " -0.36837041 -0.27332532 -0.17338663 -0.06894272 -0.02464466 -0.0069849\n",
      " -0.00477028 -0.00418943 -0.01864826 -0.05327212 -0.14042052 -0.27718062\n",
      " -0.41220901 -0.5540034  -0.69200544 -0.79258314 -0.74059213 -0.29756664\n",
      " -0.7943956  -1.09410266 -1.20489455 -1.27242541 -1.18363406 -1.07835249\n",
      " -0.06682482  1.68604937  0.93866876 -0.48675394 -0.38089678 -0.27829889\n",
      " -0.17549155 -0.07702614 -0.0296263  -0.00911024 -0.00408252 -0.00670728\n",
      " -0.02160143 -0.06070769 -0.15702241 -0.29716317 -0.4223068  -0.54572671\n",
      " -0.65910029 -0.74125055 -0.78837956 -0.83396729 -0.9194134  -1.02595562\n",
      " -1.12277551 -1.14506316 -1.0794597  -0.99988631 -0.01264694  1.69802655\n",
      "  0.91291517 -0.49307976 -0.37987428 -0.27351765 -0.17353912 -0.08405015\n",
      " -0.03416244 -0.00893965  0.         -0.00893209 -0.02539776 -0.07390018\n",
      " -0.17786005 -0.31338343 -0.42901306 -0.53508894 -0.62078199 -0.68268924\n",
      " -0.72347014 -0.76555898 -0.82507042 -0.91939024 -1.00626013 -1.03281505\n",
      " -1.01067269 -0.9515093   0.01268438  1.69351198 -0.11710038 -0.48515629\n",
      " -0.36804198 -0.26078182 -0.16833376 -0.08854264 -0.03593623 -0.01071081\n",
      " -0.00590597 -0.00635211 -0.03332021 -0.09130486 -0.19910803 -0.32796741\n",
      " -0.43899543 -0.53445409 -0.6059479  -0.65940509 -0.69784837 -0.73042289\n",
      " -0.78112567 -0.87168855 -0.95845445 -1.01124661 -1.01044884 -0.95294508\n",
      "  0.38874725  1.6951103  -0.3431014  -0.46342915 -0.34877114 -0.24588475\n",
      " -0.15820094 -0.08543796 -0.03155796 -0.00976041 -0.00408252 -0.01128166\n",
      " -0.0397571  -0.10385233 -0.21198097 -0.33747789 -0.45170193 -0.55213161\n",
      " -0.63188648 -0.69322439 -0.7383849  -0.77073077 -0.82876952 -0.91927271\n",
      " -1.0088061  -1.06082828 -1.04812373  0.13112956  1.43768764  0.50839925\n",
      " -0.51165472 -0.42707461 -0.31681048 -0.2206858  -0.14105726 -0.07817104\n",
      " -0.02918258 -0.00802579  0.         -0.0103421  -0.04327362 -0.10916701\n",
      " -0.20903257 -0.33022464 -0.45487527 -0.46338641 -0.29186344 -0.76060123\n",
      " -0.8287575  -0.88650819 -0.9598404  -1.05138397 -1.12090482 -1.12894344\n",
      " -0.77506606  1.13287468  0.82721634 -0.58603501 -0.48806277 -0.36895114\n",
      " -0.26929223 -0.18721262 -0.12162743 -0.06649382 -0.026033   -0.00577332\n",
      " -0.00408252 -0.0100095  -0.04049873 -0.09998471 -0.18820172 -0.29963131\n",
      " -0.42724847  0.93056162  0.27664896 -0.80158752 -0.90865685 -1.00894524\n",
      " -1.10362289 -1.1813322  -1.19218568 -0.03485854  1.15697368  1.19565202\n",
      "  0.28460495 -0.52269449 -0.39906543 -0.29670064 -0.21262622 -0.14869396\n",
      " -0.09689573 -0.05093109 -0.02021443 -0.00408252 -0.00408252 -0.00600491\n",
      " -0.03370635 -0.07897245 -0.14774138 -0.24325025 -0.20629049  1.91952647\n",
      "  0.93950576 -0.75670418 -0.88873651 -1.00217059 -1.08959257 -0.86773569\n",
      "  0.22622953  1.29218021  1.22402201 -0.3321922  -0.52359508 -0.40214203\n",
      " -0.30306916 -0.22168084 -0.15936594 -0.1100607  -0.07003976 -0.03713562\n",
      " -0.01220141 -0.00408252  0.          0.         -0.02273873 -0.0519054\n",
      " -0.09998802 -0.16843162 -0.26031072  1.05141697  2.59001419  1.9237492\n",
      "  1.58500656  1.38312907  1.29628889  1.33236293  1.51471874  0.49003765\n",
      " -0.52747526 -0.49207119 -0.37992817 -0.28881739 -0.21344094 -0.15366778\n",
      " -0.10912601 -0.07409876 -0.04331719 -0.01934379 -0.01040248  0.\n",
      "  0.          0.         -0.0103527  -0.0287501  -0.05756837 -0.09531054\n",
      " -0.15360976 -0.19898941  0.07527167  1.47667268  2.14588462  2.35666334\n",
      "  1.25566553  0.87282555  0.59822472 -0.4425811  -0.39580505 -0.32478945\n",
      " -0.25570503 -0.19461171 -0.14457421 -0.10177354 -0.07142522 -0.04777776\n",
      " -0.02575244 -0.01137942 -0.00475287  0.          0.          0.\n",
      " -0.0066643  -0.01096421 -0.02760445 -0.0515536  -0.08677185 -0.12839203\n",
      " -0.1757759  -0.22305444 -0.26664029 -0.29484432 -0.30750543 -0.30518012\n",
      " -0.28923178 -0.26323129 -0.23372359 -0.20102782 -0.16369105 -0.127666\n",
      " -0.09396514 -0.06568326 -0.04592653 -0.02871881 -0.01569304 -0.00567531\n",
      " -0.00408252  0.          0.          0.          0.         -0.00408252\n",
      " -0.01512139 -0.03136955 -0.05333023 -0.07922827 -0.10837665 -0.13397907\n",
      " -0.15751318 -0.17510551 -0.1826269  -0.18053534 -0.16987649 -0.15315731\n",
      " -0.13543312 -0.1164803  -0.09395125 -0.07257689 -0.05236436 -0.036383\n",
      " -0.02150306 -0.01301928 -0.00449422 -0.00408252  0.          0.\n",
      "  0.          0.          0.          0.         -0.00579016 -0.00905385\n",
      " -0.01600544 -0.02211976 -0.026846   -0.03184506 -0.04374841 -0.04728295\n",
      " -0.0531388  -0.05662282 -0.06033836 -0.056295   -0.05136654 -0.04263228\n",
      " -0.03317103 -0.02246288 -0.01606909 -0.0114322  -0.00900729 -0.00577039\n",
      "  0.          0.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = None\n",
    "X_train = None\n",
    "if train_model:\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform( X_train_raw )\n",
    "else:\n",
    "    scaler = load( scaler_path )\n",
    "    X_train = scaler.transform( X_train_raw )\n",
    "X_test  = scaler.transform( X_test_raw )\n",
    "\n",
    "print ( scaler )\n",
    "\n",
    "if train_model and save_model:\n",
    "#     dump( scaler, \"standard_scaler.joblib\")\n",
    "    dump( scaler, \"models/standard_scaler.joblib\")\n",
    "    \n",
    "idx = 20000\n",
    "print ( y_train[ idx ] )\n",
    "print ( X_train[ idx ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "id": "Oeic-Yz9VPpt",
    "outputId": "cfd13dbd-9a7f-4987-b57a-3864e44b2314"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26332cdd148>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkEAAAI/CAYAAABwLA0cAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAW6klEQVR4nO3dbYyldZnn8d+FpRLwCUKrxEG7VULWSAbXkqxhQzQjo6NE5cVsBo32Gg2+GImaARd8A0bXBzLiJrohgUBkIzqZBByIMeuoMSgJIXYTFJAZ8KFnRAm0MT6MxEyQ/77oQ7bDdNNt9//Uaer6fJJOVd11+jpXuDnd375PnaoaYwQAoJujVr0AAMAqiCAAoCURBAC0JIIAgJZEEADQkggCAFpa28g7O+GEE8bWrVs38i4BgOZ27tz5izHGlscf39AI2rp1a3bs2LGRdwkANFdV/7Kv454OAwBaEkEAQEsiCABoSQQBAC0dVgRV1Ruq6p+r6odVddGspQAAlu2QI6iqnpLkfyf5iyQvS3JuVb1s1mIAAMt0OFeCTk/ywzHGj8cY/57k75K8Zc5aAADLdTgR9IIkP93r4/sXxwAAjniHE0G1j2PjP9yo6ryq2lFVO3bv3n0YdwcAMM/hRND9SU7a6+M/SfLzx99ojHHlGGN9jLG+Zct/+I7VAAArcTgR9N0kJ1fVtqp6WpK/SnLTnLUAAJbrkH922Bjjkap6X5KvJXlKkmvGGHdP2wwAYIkO6weojjG+muSrk3YBANgwvmM0ANCSCAIAWhJBAEBLIggAaEkEAQAtiSAAoCURBAC0JIIAgJZEEADQkggCAFoSQQBASyIIAGhJBAEALYkgAKAlEQQAtCSCAICWRBAA0JIIAgBaEkEAQEsiCABoSQQBAC2JIACgJREEALQkggCAlkQQANCSCAIAWhJBAEBLIggAaEkEAQAtiSAAoCURBAC0JIIAgJZEEADQkggCAFoSQQBASyIIAGhJBAEALYkgAKAlEQQAtCSCAICWRBAA0JIIAgBaEkEAQEsiCABoSQQBAC2JIACgJREEALQkggCAlkQQANCSCAIAWhJBAEBLIggAaEkEAQAtiSAAoCURBAC0JIIAgJZEEADQkggCAFoSQQBASyIIAGhJBAEALYkgAKAlEQQAtCSCAICWRBAA0JIIAgBaEkEAQEsiCABoSQQBAC2JIACgJREEALQkggCAlkQQANCSCAIAWhJBAEBLIggAaEkEAQAtiSAAoCURBAC0JIIAgJZEEADQkggCAFpaW/UC0M2jjz46dd511103bda99947bdZsP/nJT6bNuu2226bNSpJLLrlk2qy3ve1t02YlyVFH+bcu7I9HBwDQkggCAFoSQQBASyIIAGhJBAEALR3Wq8OqaleS3yb5Q5JHxhjrM5YCAFi2GS+Rf+0Y4xcT5gAAbBhPhwEALR1uBI0k/1hVO6vqvBkLAQBshMN9OuyMMcbPq+q5Sb5eVf80xvj23jdYxNF5SfLCF77wMO8OAGCOw7oSNMb4+eLtQ0m+nOT0fdzmyjHG+hhjfcuWLYdzdwAA0xxyBFXVsVX1zMfeT/LnSe6atRgAwDIdztNhz0vy5ap6bM4Xxxj/d8pWAABLdsgRNMb4cZI/nbgLAMCG8RJ5AKAlEQQAtCSCAICWRBAA0JIIAgBamvEDVGHTe/TRR6fNuvzyy6fNSpILL7xw6rwOnv70p0+d9453vGParFNOOWXarCR55StfOW3WUUf5dzObi/+jAYCWRBAA0JIIAgBaEkEAQEsiCABoSQQBAC2JIACgJREEALQkggCAlkQQANCSCAIAWhJBAEBLIggAaEkEAQAtiSAAoCURBAC0JIIAgJZEEADQ0tqqF4AngzvvvHParAsvvHDarNme9axnTZ33rne9a9qsm2++edqsc845Z9qsJLnkkkumzTr99NOnzUqSe++9d9qsk08+edosOBK4EgQAtCSCAICWRBAA0JIIAgBaEkEAQEsiCABoSQQBAC2JIACgJREEALQkggCAlkQQANCSCAIAWhJBAEBLIggAaEkEAQAtiSAAoCURBAC0JIIAgJbWVr0ALMMXvvCFqfM+9rGPTZv1nOc8Z9qsJNm+ffu0WR/84AenzUqSF73oRVPnzfKVr3xl1Svs19FHHz113tqaP+Zhf1wJAgBaEkEAQEsiCABoSQQBAC2JIACgJREEALQkggCAlkQQANCSCAIAWhJBAEBLIggAaEkEAQAtiSAAoCURBAC0JIIAgJZEEADQkggCAFoSQQBASyIIAGhpbdULwDLceeedU+cdc8wx02bt3Llz2qwkefGLXzx1Xge/+tWvVr3Cfl111VVT523btm3qPNhMXAkCAFoSQQBASyIIAGhJBAEALYkgAKAlEQQAtCSCAICWRBAA0JIIAgBaEkEAQEsiCABoSQQBAC2JIACgJREEALQkggCAlkQQANCSCAIAWhJBAEBLNcbYsDtbX18fO3bs2LD7AzaP3/3ud9NmnXHGGdNmJcmPfvSjabNuv/32abOS5OSTT546D56MqmrnGGP98cddCQIAWhJBAEBLIggAaEkEAQAtiSAAoKUDRlBVXVNVD1XVXXsdO76qvl5V9y3eHrfcNQEA5jqYK0GfT/KGxx27KMk3xxgnJ/nm4mMAgCeNA0bQGOPbSX75uMNvSXLt4v1rk7x17loAAMt1qF8T9LwxxgNJsnj73HkrAQAs39K/MLqqzquqHVW1Y/fu3cu+OwCAg3KoEfRgVZ2YJIu3D+3vhmOMK8cY62OM9S1bthzi3QEAzHWoEXRTku2L97cnuXHOOgAAG+NgXiL/pSS3Jjmlqu6vqncn+WSSs6rqviRnLT4GAHjSWDvQDcYY5+7nU382eRcAgA3jO0YDAC2JIACgJREEALQkggCAlkQQANDSAV8dBnAkuOCCC6bN+t73vjdtVpK87nWvmzbrpJNOmjYLeGKuBAEALYkgAKAlEQQAtCSCAICWRBAA0JIIAgBaEkEAQEsiCABoSQQBAC2JIACgJREEALQkggCAlkQQANCSCAIAWhJBAEBLIggAaEkEAQAtiSAAoKW1VS8AHJ6HH3542qxvfOMb02Ylyec///lps77zne9MmzXbzP9ub3rTm6bNSpKLL7542qwzzzxz2qwkedrTnjZ1HvyxXAkCAFoSQQBASyIIAGhJBAEALYkgAKAlEQQAtCSCAICWRBAA0JIIAgBaEkEAQEsiCABoSQQBAC2JIACgJREEALQkggCAlkQQANCSCAIAWhJBAEBLIggAaGlt1QtAN7fccsvUeRdffPG0WbN3O1KdeuqpU+cde+yx02bdeuut02YlyVlnnTVt1mtf+9pps5Lk+uuvnzbruOOOmzaLPlwJAgBaEkEAQEsiCABoSQQBAC2JIACgJREEALQkggCAlkQQANCSCAIAWhJBAEBLIggAaEkEAQAtiSAAoCURBAC0JIIAgJZEEADQkggCAFoSQQBAS2urXgC6uemmm6bOu+WWW6bNOvXUU6fNSpLzzz9/2qxt27ZNm/WqV71q2qwkefaznz1t1q233jptVpLceOON02Z96lOfmjYrSa6++uppsy644IJps+jDlSAAoCURBAC0JIIAgJZEEADQkggCAFoSQQBASyIIAGhJBAEALYkgAKAlEQQAtCSCAICWRBAA0JIIAgBaEkEAQEsiCABoSQQBAC2JIACgJREEALS0tuoFoJtLLrlk6ryzzz572qyXv/zl02YlyfHHHz91XgevfvWrp8677777ps6badeuXategeZcCQIAWhJBAEBLIggAaEkEAQAtiSAAoKUDRlBVXVNVD1XVXXsdu7SqflZVdyx+vXG5awIAzHUwV4I+n+QN+zj+mTHGaYtfX527FgDAch0wgsYY307yyw3YBQBgwxzO1wS9r6q+v3i67LhpGwEAbIBDjaArkrwkyWlJHkjy6f3dsKrOq6odVbVj9+7dh3h3AABzHVIEjTEeHGP8YYzxaJKrkpz+BLe9coyxPsZY37Jly6HuCQAw1SFFUFWduNeH5yS5a3+3BQA4Eh3wB6hW1ZeSvCbJCVV1f5JLkrymqk5LMpLsSvLe5a0IADDfASNojHHuPg5fvYRdAAA2jO8YDQC0JIIAgJZEEADQkggCAFoSQQBASwd8dRgw17HHHjt13plnnjl1HkAXrgQBAC2JIACgJREEALQkggCAlkQQANCSCAIAWhJBAEBLIggAaEkEAQAtiSAAoCURBAC0JIIAgJZEEADQkggCAFoSQQBASyIIAGhJBAEALYkgAKCltVUvAEBP73nPe1a9As25EgQAtCSCAICWRBAA0JIIAgBaEkEAQEsiCABoSQQBAC2JIACgJREEALQkggCAlkQQANCSCAIAWhJBAEBLIggAaEkEAQAtiSAAoCURBAC0JIIAgJZEEADQ0tqqFwBgeX7wgx+seoX9ev7zn7/qFWjOlSAAoCURBAC0JIIAgJZEEADQkggCAFoSQQBASyIIAGhJBAEALYkgAKAlEQQAtCSCAICWRBAA0JIIAgBaEkEAQEsiCABoSQQBAC2JIACgJREEALS0tuoFAPj/Pv7xj0+d95nPfGbarI9+9KPTZiXJCSecMHUe/LFcCQIAWhJBAEBLIggAaEkEAQAtiSAAoCURBAC0JIIAgJZEEADQkggCAFoSQQBASyIIAGhJBAEALYkgAKAlEQQAtCSCAICWRBAA0JIIAgBaEkEAQEsiCABoaW3VC8BjHn744WmzfvrTn06blSSnnHLK1HlsLrt27Zo263Of+9y0WUly9tlnT5t10UUXTZuVJGtr/gpitVwJAgBaEkEAQEsiCABoSQQBAC0dMIKq6qSq+lZV3VNVd1fV+xfHj6+qr1fVfYu3xy1/XQCAOQ7mStAjSf5mjPGfkvyXJH9dVS9LclGSb44xTk7yzcXHAABPCgeMoDHGA2OM2xfv/zbJPUlekOQtSa5d3OzaJG9d0o4AANP9UV8TVFVbk7wiyW1JnjfGeCDZE0pJnjt9OwCAJTnoCKqqZyS5PskHxhi/+SN+33lVtaOqduzevftQdgQAmO6gIqiqnpo9AXTdGOOGxeEHq+rExedPTPLQvn7vGOPKMcb6GGN9y5YtM3YGADhsB/PqsEpydZJ7xhiX7/Wpm5JsX7y/PcmN89cDAFiOg/nBLWckeUeSO6vqjsWxDyf5ZJK/r6p3J/nXJH+5lA0BAJbggBE0xrglSe3n0382dx0AgI3hO0YDAC2JIACgJREEALQkggCAlkQQANDSwbxEHjbEpZdeOm3WKaecMm3WMuaxWp/4xCemzrvsssumzZr9TWXf/OY3T5u1tuavDDYXV4IAgJZEEADQkggCAFoSQQBASyIIAGhJBAEALYkgAKAlEQQAtCSCAICWRBAA0JIIAgBaEkEAQEsiCABoSQQBAC2JIACgJREEALQkggCAlkQQANDS2qoX4Mnt4Ycfnjbr5ptvnjbr17/+9bRZSfLud7976rwu7r///mmzLrvssmmzrrjiimmzkmTr1q3TZn3ta1+bNitJtm3bNnUebCauBAEALYkgAKAlEQQAtCSCAICWRBAA0JIIAgBaEkEAQEsiCABoSQQBAC2JIACgJREEALQkggCAlkQQANCSCAIAWhJBAEBLIggAaEkEAQAtiSAAoCURBAC0tLbqBXhyO+aYY6bNOv/886fNeuc73zltVpJ88YtfnDqvi0ceeWTarN///vfTZn3kIx+ZNitJPvShD02bdfTRR0+bBTwxV4IAgJZEEADQkggCAFoSQQBASyIIAGhJBAEALYkgAKAlEQQAtCSCAICWRBAA0JIIAgBaEkEAQEsiCABoSQQBAC2JIACgJREEALQkggCAlkQQANDS2qoXgMe8/e1vnzbr9a9//bRZSfLZz3522qwbbrhh2qwkufvuu6fNOvfcc6fNSpKXvvSl02Zt27Zt2qzt27dPm5UkRx3l35PwZOSRCwC0JIIAgJZEEADQkggCAFoSQQBASyIIAGhJBAEALYkgAKAlEQQAtCSCAICWRBAA0JIIAgBaEkEAQEsiCABoSQQBAC2JIACgJREEALQkggCAlkQQANBSjTE27M7W19fHjh07Nuz+AACqaucYY/3xx10JAgBaEkEAQEsiCABoSQQBAC0dMIKq6qSq+lZV3VNVd1fV+xfHL62qn1XVHYtfb1z+ugAAc6wdxG0eSfI3Y4zbq+qZSXZW1dcXn/vMGONvl7ceAMByHDCCxhgPJHlg8f5vq+qeJC9Y9mIAAMv0R31NUFVtTfKKJLctDr2vqr5fVddU1XGzlwMAWJaDjqCqekaS65N8YIzxmyRXJHlJktOy50rRp/fz+86rqh1VtWP37t2HvzEAwAQHFUFV9dTsCaDrxhg3JMkY48Exxh/GGI8muSrJ6fv6vWOMK8cY62OM9S1btszaGwDgsBzMq8MqydVJ7hljXL7X8RP3utk5Se6avx4AwHIczKvDzkjyjiR3VtUdi2MfTnJuVZ2WZCTZleS9S9gPAGApDubVYbckqX186qvz1wEA2Bi+YzQA0JIIAgBaEkEAQEsiCABoSQQBAC2JIACgJREEALQkggCAlkQQANCSCAIAWhJBAEBLIggAaEkEAQAtiSAAoCURBAC0JIIAgJZEEADQkggCAFoSQQBASyIIAGhJBAEALYkgAKAlEQQAtCSCAICWRBAA0JIIAgBaEkEAQEsiCABoSQQBAC2JIACgJREEALQkggCAlkQQANCSCAIAWhJBAEBLIggAaEkEAQAtiSAAoCURBAC0JIIAgJZEEADQkggCAFoSQQBASyIIAGipxhgbd2dVu5P8y0Hc9IQkv1jyOjwx52D1nIPVcw5WzzlYvc1wDl40xtjy+IMbGkEHq6p2jDHWV71HZ87B6jkHq+ccrJ5zsHqb+Rx4OgwAaEkEAQAtHakRdOWqF8A5OAI4B6vnHKyec7B6m/YcHJFfEwQAsGxH6pUgAIClOqIiqKreUFX/XFU/rKqLVr1PR1W1q6rurKo7qmrHqvfpoqquqaqHququvY4dX1Vfr6r7Fm+PW+WOm91+zsGlVfWzxePhjqp64yp33Myq6qSq+lZV3VNVd1fV+xfHPQ42yBOcg037ODhing6rqqckuTfJWUnuT/LdJOeOMX6w0sWaqapdSdbHGE/27wnxpFJVZyb5tyT/Z4zx8sWxy5L8cozxycU/Co4bY/yPVe65me3nHFya5N/GGH+7yt06qKoTk5w4xri9qp6ZZGeStyb57/E42BBPcA7+Wzbp4+BIuhJ0epIfjjF+PMb49yR/l+QtK94JNsQY49tJfvm4w29Jcu3i/Wuz5w8jlmQ/54ANMsZ4YIxx++L93ya5J8kL4nGwYZ7gHGxaR1IEvSDJT/f6+P5s8v/4R6iR5B+ramdVnbfqZZp73hjjgWTPH05Jnrvifbp6X1V9f/F0madiNkBVbU3yiiS3xeNgJR53DpJN+jg4kiKo9nHsyHiurpczxhj/OclfJPnrxVME0NUVSV6S5LQkDyT59Eq3aaCqnpHk+iQfGGP8ZtX7dLSPc7BpHwdHUgTdn+SkvT7+kyQ/X9EubY0xfr54+1CSL2fP05SsxoOL5+gfe67+oRXv084Y48Exxh/GGI8muSoeD0tVVU/Nnr98rxtj3LA47HGwgfZ1Djbz4+BIiqDvJjm5qrZV1dOS/FWSm1a8UytVdezii+FSVccm+fMkdz3x72KJbkqyffH+9iQ3rnCXlh77y3fhnHg8LE1VVZKrk9wzxrh8r095HGyQ/Z2Dzfw4OGJeHZYki5fd/a8kT0lyzRjjf652o16q6sXZc/UnSdaSfNE52BhV9aUkr8men9b8YJJLkvxDkr9P8sIk/5rkL8cYvnB3SfZzDl6TPU8BjCS7krz3sa9PYa6q+q9JvpPkziSPLg5/OHu+JsXjYAM8wTk4N5v0cXBERRAAwEY5kp4OAwDYMCIIAGhJBAEALYkgAKAlEQQAtCSCAICWRBAA0JIIAgBa+n8EhNvPsG016QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure( figsize=(10,10) )\n",
    "plt.imshow( X_train_raw[ idx ].reshape(28,28), cmap='binary' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wbc4SQB_UIvP"
   },
   "source": [
    "### Treinamento\n",
    "### Hyperparameter scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "d60gu_8uVimN"
   },
   "outputs": [],
   "source": [
    "shuffle_index = np.random.permutation( 60000 )\n",
    "X_train_shuffle, y_train_shuffle = X_train[ shuffle_index ], y_train[ shuffle_index ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nlqzcg5xUJYw",
    "outputId": "67847736-e359-4c02-dcfb-aef365e50021"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/04/11 08:01:05\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=6)]: Done   2 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=6)]: Done   3 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=6)]: Done   4 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=6)]: Done   5 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=6)]: Done   7 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=6)]: Done   8 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=6)]: Done   9 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=6)]: Done  10 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=6)]: Done  11 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=6)]: Done  12 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=6)]: Done  14 tasks      | elapsed:  9.3min\n",
      "[Parallel(n_jobs=6)]: Done  15 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=6)]: Done  16 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=6)]: Done  17 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=6)]: Done  18 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=6)]: Done  19 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=6)]: Done  21 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=6)]: Done  22 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=6)]: Done  23 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=6)]: Done  24 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=6)]: Done  25 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=6)]: Done  26 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=6)]: Done  27 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=6)]: Done  28 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed: 15.1min\n",
      "[Parallel(n_jobs=6)]: Done  30 tasks      | elapsed: 15.2min\n",
      "[Parallel(n_jobs=6)]: Done  31 tasks      | elapsed: 16.5min\n",
      "[Parallel(n_jobs=6)]: Done  32 tasks      | elapsed: 16.5min\n",
      "[Parallel(n_jobs=6)]: Done  33 tasks      | elapsed: 18.0min\n",
      "[Parallel(n_jobs=6)]: Done  34 tasks      | elapsed: 18.0min\n",
      "[Parallel(n_jobs=6)]: Done  35 tasks      | elapsed: 19.0min\n",
      "[Parallel(n_jobs=6)]: Done  36 tasks      | elapsed: 19.1min\n",
      "[Parallel(n_jobs=6)]: Done  37 tasks      | elapsed: 19.2min\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed: 19.2min\n",
      "[Parallel(n_jobs=6)]: Done  39 tasks      | elapsed: 20.8min\n",
      "[Parallel(n_jobs=6)]: Done  40 tasks      | elapsed: 20.8min\n",
      "[Parallel(n_jobs=6)]: Done  41 tasks      | elapsed: 23.8min\n",
      "[Parallel(n_jobs=6)]: Done  42 tasks      | elapsed: 23.9min\n",
      "[Parallel(n_jobs=6)]: Done  43 tasks      | elapsed: 24.0min\n",
      "[Parallel(n_jobs=6)]: Done  44 tasks      | elapsed: 24.1min\n",
      "[Parallel(n_jobs=6)]: Done  45 tasks      | elapsed: 24.6min\n",
      "[Parallel(n_jobs=6)]: Done  46 tasks      | elapsed: 24.6min\n",
      "[Parallel(n_jobs=6)]: Done  47 tasks      | elapsed: 27.6min\n",
      "[Parallel(n_jobs=6)]: Done  48 tasks      | elapsed: 27.6min\n",
      "[Parallel(n_jobs=6)]: Done  49 tasks      | elapsed: 27.8min\n",
      "[Parallel(n_jobs=6)]: Done  50 tasks      | elapsed: 27.9min\n",
      "[Parallel(n_jobs=6)]: Done  51 tasks      | elapsed: 28.4min\n",
      "[Parallel(n_jobs=6)]: Done  52 tasks      | elapsed: 28.4min\n",
      "[Parallel(n_jobs=6)]: Done  53 tasks      | elapsed: 30.8min\n",
      "[Parallel(n_jobs=6)]: Done  54 tasks      | elapsed: 30.8min\n",
      "[Parallel(n_jobs=6)]: Done  55 tasks      | elapsed: 31.2min\n",
      "[Parallel(n_jobs=6)]: Done  56 tasks      | elapsed: 31.2min\n",
      "[Parallel(n_jobs=6)]: Done  57 tasks      | elapsed: 31.4min\n",
      "[Parallel(n_jobs=6)]: Done  58 tasks      | elapsed: 31.5min\n",
      "[Parallel(n_jobs=6)]: Done  59 tasks      | elapsed: 33.1min\n",
      "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed: 33.1min\n",
      "[Parallel(n_jobs=6)]: Done  61 tasks      | elapsed: 33.3min\n",
      "[Parallel(n_jobs=6)]: Done  62 tasks      | elapsed: 33.3min\n",
      "[Parallel(n_jobs=6)]: Done  63 tasks      | elapsed: 33.4min\n",
      "[Parallel(n_jobs=6)]: Done  64 tasks      | elapsed: 33.4min\n",
      "[Parallel(n_jobs=6)]: Done  65 tasks      | elapsed: 36.3min\n",
      "[Parallel(n_jobs=6)]: Done  66 tasks      | elapsed: 36.3min\n",
      "[Parallel(n_jobs=6)]: Done  67 tasks      | elapsed: 36.6min\n",
      "[Parallel(n_jobs=6)]: Done  68 tasks      | elapsed: 36.6min\n",
      "[Parallel(n_jobs=6)]: Done  69 tasks      | elapsed: 36.7min\n",
      "[Parallel(n_jobs=6)]: Done  70 tasks      | elapsed: 36.7min\n",
      "[Parallel(n_jobs=6)]: Done  71 tasks      | elapsed: 39.2min\n",
      "[Parallel(n_jobs=6)]: Done  72 tasks      | elapsed: 39.2min\n",
      "[Parallel(n_jobs=6)]: Done  73 tasks      | elapsed: 40.2min\n",
      "[Parallel(n_jobs=6)]: Done  74 tasks      | elapsed: 40.3min\n",
      "[Parallel(n_jobs=6)]: Done  75 tasks      | elapsed: 40.4min\n",
      "[Parallel(n_jobs=6)]: Done  76 tasks      | elapsed: 40.4min\n",
      "[Parallel(n_jobs=6)]: Done  77 tasks      | elapsed: 42.1min\n",
      "[Parallel(n_jobs=6)]: Done  78 tasks      | elapsed: 42.1min\n",
      "[Parallel(n_jobs=6)]: Done  79 tasks      | elapsed: 43.2min\n",
      "[Parallel(n_jobs=6)]: Done  80 tasks      | elapsed: 43.2min\n",
      "[Parallel(n_jobs=6)]: Done  81 tasks      | elapsed: 43.9min\n",
      "[Parallel(n_jobs=6)]: Done  82 tasks      | elapsed: 43.9min\n",
      "[Parallel(n_jobs=6)]: Done  83 tasks      | elapsed: 45.5min\n",
      "[Parallel(n_jobs=6)]: Done  84 tasks      | elapsed: 45.5min\n",
      "[Parallel(n_jobs=6)]: Done  85 tasks      | elapsed: 49.2min\n",
      "[Parallel(n_jobs=6)]: Done  86 tasks      | elapsed: 49.2min\n",
      "[Parallel(n_jobs=6)]: Done  87 tasks      | elapsed: 49.9min\n",
      "[Parallel(n_jobs=6)]: Done  88 tasks      | elapsed: 49.9min\n",
      "[Parallel(n_jobs=6)]: Done  89 tasks      | elapsed: 50.3min\n",
      "[Parallel(n_jobs=6)]: Done  90 tasks      | elapsed: 50.3min\n",
      "[Parallel(n_jobs=6)]: Done  91 tasks      | elapsed: 53.4min\n",
      "[Parallel(n_jobs=6)]: Done  92 tasks      | elapsed: 53.5min\n",
      "[Parallel(n_jobs=6)]: Done  93 tasks      | elapsed: 53.9min\n",
      "[Parallel(n_jobs=6)]: Done  94 tasks      | elapsed: 53.9min\n",
      "[Parallel(n_jobs=6)]: Done  95 tasks      | elapsed: 53.9min\n",
      "[Parallel(n_jobs=6)]: Done  96 tasks      | elapsed: 54.0min\n",
      "[Parallel(n_jobs=6)]: Done  97 tasks      | elapsed: 56.0min\n",
      "[Parallel(n_jobs=6)]: Done  98 tasks      | elapsed: 56.0min\n",
      "[Parallel(n_jobs=6)]: Done  99 tasks      | elapsed: 58.1min\n",
      "[Parallel(n_jobs=6)]: Done 100 tasks      | elapsed: 58.1min\n",
      "[Parallel(n_jobs=6)]: Done 101 tasks      | elapsed: 58.2min\n",
      "[Parallel(n_jobs=6)]: Done 102 tasks      | elapsed: 58.3min\n",
      "[Parallel(n_jobs=6)]: Done 103 tasks      | elapsed: 58.7min\n",
      "[Parallel(n_jobs=6)]: Done 104 tasks      | elapsed: 58.7min\n",
      "[Parallel(n_jobs=6)]: Done 105 tasks      | elapsed: 60.1min\n",
      "[Parallel(n_jobs=6)]: Done 106 tasks      | elapsed: 60.1min\n",
      "[Parallel(n_jobs=6)]: Done 107 tasks      | elapsed: 60.1min\n",
      "[Parallel(n_jobs=6)]: Done 108 tasks      | elapsed: 60.1min\n",
      "[Parallel(n_jobs=6)]: Done 109 tasks      | elapsed: 60.3min\n",
      "[Parallel(n_jobs=6)]: Done 116 out of 120 | elapsed: 63.1min remaining:  2.2min\n",
      "[Parallel(n_jobs=6)]: Done 120 out of 120 | elapsed: 64.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 500, 'learning_rate': 0.30000000000000004, 'base_estimator__min_samples_split': 3, 'base_estimator__max_depth': 4}\n",
      "0.9105000000000001\n",
      "{'mean_fit_time': array([207.38443434, 197.12308598, 225.70349556, 214.6189521 ,\n",
      "       112.80433637,  81.00611484, 142.61941046, 167.60449833,\n",
      "       227.34529495, 162.20973021, 283.67949289, 225.21092552,\n",
      "       223.62292123, 213.92221951, 143.26989186, 113.40360808,\n",
      "       203.93022025, 170.93351376, 215.33593601, 172.38483322,\n",
      "       202.23038733, 355.4879837 , 284.22419477, 211.73229456,\n",
      "       283.42839062, 120.62245142, 121.36466002,  82.48331457,\n",
      "       163.57257789, 121.75319326]), 'std_fit_time': array([ 0.41699793,  4.10098808,  0.90255005,  0.45665939,  1.49899914,\n",
      "        0.68759942,  0.59720007,  1.260374  ,  0.99437694,  0.72443512,\n",
      "        0.46363889,  2.00403234,  0.88020583,  0.59717481,  1.03829246,\n",
      "        0.48103308,  0.61933919,  1.58042386,  0.24262766,  1.13115061,\n",
      "        2.00095072,  0.64658099,  1.16938211,  0.62199606,  0.36911529,\n",
      "        1.2010957 ,  0.60021759,  1.55211915,  0.33933783, 13.47971945]), 'mean_score_time': array([3.11881787, 4.55243897, 3.9968223 , 2.81142557, 1.83530569,\n",
      "       1.81519514, 1.81272131, 2.78814185, 3.78074771, 3.72338098,\n",
      "       4.5834794 , 3.60276788, 3.56626719, 2.67266846, 1.79763502,\n",
      "       1.82534593, 4.63210213, 2.82856107, 2.73002511, 2.78833389,\n",
      "       4.67847633, 4.60209036, 3.65015584, 2.78967077, 4.76933175,\n",
      "       2.7141943 , 2.84687334, 1.94774961, 3.62404132, 1.27663362]), 'std_score_time': array([0.05396673, 0.085253  , 0.07342912, 0.05261117, 0.06326487,\n",
      "       0.02656194, 0.02284961, 0.11201757, 0.12188065, 0.06731196,\n",
      "       0.19016589, 0.06599653, 0.02353129, 0.10220379, 0.05999983,\n",
      "       0.04138006, 0.06106099, 0.07020807, 0.10163138, 0.02174147,\n",
      "       0.04384478, 0.06373548, 0.06378486, 0.04265704, 0.06237931,\n",
      "       0.01923152, 0.05340434, 0.05339579, 0.14696077, 0.20748166]), 'param_n_estimators': masked_array(data=[300, 500, 400, 300, 200, 200, 200, 300, 400, 400, 500,\n",
      "                   400, 400, 300, 200, 200, 500, 300, 300, 300, 500, 500,\n",
      "                   400, 300, 500, 300, 300, 200, 400, 200],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_learning_rate': masked_array(data=[0.30000000000000004, 0.2, 0.2, 0.2, 0.4, 0.5,\n",
      "                   0.30000000000000004, 0.2, 0.2, 0.2, 0.2, 0.5, 0.5,\n",
      "                   0.30000000000000004, 0.30000000000000004, 0.2, 0.4,\n",
      "                   0.30000000000000004, 0.5, 0.4, 0.4,\n",
      "                   0.30000000000000004, 0.5, 0.2, 0.30000000000000004,\n",
      "                   0.5, 0.4, 0.30000000000000004, 0.4, 0.5],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_base_estimator__min_samples_split': masked_array(data=[3, 3, 4, 2, 2, 2, 4, 3, 3, 3, 2, 3, 4, 4, 2, 3, 3, 3,\n",
      "                   3, 3, 2, 3, 2, 3, 2, 4, 2, 2, 3, 3],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_base_estimator__max_depth': masked_array(data=[4, 2, 3, 4, 3, 2, 4, 3, 3, 2, 3, 3, 3, 4, 4, 3, 2, 3,\n",
      "                   4, 3, 2, 4, 4, 4, 3, 2, 2, 2, 2, 4],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'n_estimators': 300, 'learning_rate': 0.30000000000000004, 'base_estimator__min_samples_split': 3, 'base_estimator__max_depth': 4}, {'n_estimators': 500, 'learning_rate': 0.2, 'base_estimator__min_samples_split': 3, 'base_estimator__max_depth': 2}, {'n_estimators': 400, 'learning_rate': 0.2, 'base_estimator__min_samples_split': 4, 'base_estimator__max_depth': 3}, {'n_estimators': 300, 'learning_rate': 0.2, 'base_estimator__min_samples_split': 2, 'base_estimator__max_depth': 4}, {'n_estimators': 200, 'learning_rate': 0.4, 'base_estimator__min_samples_split': 2, 'base_estimator__max_depth': 3}, {'n_estimators': 200, 'learning_rate': 0.5, 'base_estimator__min_samples_split': 2, 'base_estimator__max_depth': 2}, {'n_estimators': 200, 'learning_rate': 0.30000000000000004, 'base_estimator__min_samples_split': 4, 'base_estimator__max_depth': 4}, {'n_estimators': 300, 'learning_rate': 0.2, 'base_estimator__min_samples_split': 3, 'base_estimator__max_depth': 3}, {'n_estimators': 400, 'learning_rate': 0.2, 'base_estimator__min_samples_split': 3, 'base_estimator__max_depth': 3}, {'n_estimators': 400, 'learning_rate': 0.2, 'base_estimator__min_samples_split': 3, 'base_estimator__max_depth': 2}, {'n_estimators': 500, 'learning_rate': 0.2, 'base_estimator__min_samples_split': 2, 'base_estimator__max_depth': 3}, {'n_estimators': 400, 'learning_rate': 0.5, 'base_estimator__min_samples_split': 3, 'base_estimator__max_depth': 3}, {'n_estimators': 400, 'learning_rate': 0.5, 'base_estimator__min_samples_split': 4, 'base_estimator__max_depth': 3}, {'n_estimators': 300, 'learning_rate': 0.30000000000000004, 'base_estimator__min_samples_split': 4, 'base_estimator__max_depth': 4}, {'n_estimators': 200, 'learning_rate': 0.30000000000000004, 'base_estimator__min_samples_split': 2, 'base_estimator__max_depth': 4}, {'n_estimators': 200, 'learning_rate': 0.2, 'base_estimator__min_samples_split': 3, 'base_estimator__max_depth': 3}, {'n_estimators': 500, 'learning_rate': 0.4, 'base_estimator__min_samples_split': 3, 'base_estimator__max_depth': 2}, {'n_estimators': 300, 'learning_rate': 0.30000000000000004, 'base_estimator__min_samples_split': 3, 'base_estimator__max_depth': 3}, {'n_estimators': 300, 'learning_rate': 0.5, 'base_estimator__min_samples_split': 3, 'base_estimator__max_depth': 4}, {'n_estimators': 300, 'learning_rate': 0.4, 'base_estimator__min_samples_split': 3, 'base_estimator__max_depth': 3}, {'n_estimators': 500, 'learning_rate': 0.4, 'base_estimator__min_samples_split': 2, 'base_estimator__max_depth': 2}, {'n_estimators': 500, 'learning_rate': 0.30000000000000004, 'base_estimator__min_samples_split': 3, 'base_estimator__max_depth': 4}, {'n_estimators': 400, 'learning_rate': 0.5, 'base_estimator__min_samples_split': 2, 'base_estimator__max_depth': 4}, {'n_estimators': 300, 'learning_rate': 0.2, 'base_estimator__min_samples_split': 3, 'base_estimator__max_depth': 4}, {'n_estimators': 500, 'learning_rate': 0.30000000000000004, 'base_estimator__min_samples_split': 2, 'base_estimator__max_depth': 3}, {'n_estimators': 300, 'learning_rate': 0.5, 'base_estimator__min_samples_split': 4, 'base_estimator__max_depth': 2}, {'n_estimators': 300, 'learning_rate': 0.4, 'base_estimator__min_samples_split': 2, 'base_estimator__max_depth': 2}, {'n_estimators': 200, 'learning_rate': 0.30000000000000004, 'base_estimator__min_samples_split': 2, 'base_estimator__max_depth': 2}, {'n_estimators': 400, 'learning_rate': 0.4, 'base_estimator__min_samples_split': 3, 'base_estimator__max_depth': 2}, {'n_estimators': 200, 'learning_rate': 0.5, 'base_estimator__min_samples_split': 3, 'base_estimator__max_depth': 4}], 'split0_test_score': array([0.8936, 0.8268, 0.876 , 0.9036, 0.8412, 0.7724, 0.8908, 0.8724,\n",
      "       0.8708, 0.8256, 0.8828, 0.8756, 0.8736, 0.8964, 0.8936, 0.8592,\n",
      "       0.8028, 0.8716, 0.896 , 0.8564, 0.816 , 0.91  , 0.9056, 0.8972,\n",
      "       0.8816, 0.7684, 0.7892, 0.8012, 0.798 , 0.8888]), 'split1_test_score': array([0.9052, 0.8188, 0.8768, 0.9064, 0.856 , 0.7432, 0.8872, 0.876 ,\n",
      "       0.874 , 0.8164, 0.8776, 0.8808, 0.8668, 0.9064, 0.9   , 0.8708,\n",
      "       0.802 , 0.8752, 0.9024, 0.8624, 0.814 , 0.91  , 0.9092, 0.9052,\n",
      "       0.886 , 0.792 , 0.8032, 0.8028, 0.7876, 0.8864]), 'split2_test_score': array([0.9096, 0.8296, 0.898 , 0.912 , 0.87  , 0.7712, 0.9064, 0.8928,\n",
      "       0.8984, 0.8352, 0.8964, 0.884 , 0.8784, 0.9128, 0.8992, 0.8764,\n",
      "       0.7912, 0.886 , 0.9008, 0.8816, 0.81  , 0.916 , 0.9216, 0.914 ,\n",
      "       0.8932, 0.7796, 0.7948, 0.8184, 0.8056, 0.8916]), 'split3_test_score': array([0.8944, 0.8304, 0.88  , 0.8996, 0.8576, 0.7772, 0.8896, 0.876 ,\n",
      "       0.8724, 0.83  , 0.8768, 0.8752, 0.868 , 0.8988, 0.8908, 0.872 ,\n",
      "       0.7932, 0.8672, 0.8924, 0.866 , 0.8084, 0.906 , 0.896 , 0.906 ,\n",
      "       0.8756, 0.784 , 0.8036, 0.8036, 0.8032, 0.884 ]), 'mean_test_score': array([0.9007, 0.8264, 0.8827, 0.9054, 0.8562, 0.766 , 0.8935, 0.8793,\n",
      "       0.8789, 0.8268, 0.8834, 0.8789, 0.8717, 0.9036, 0.8959, 0.8696,\n",
      "       0.7973, 0.875 , 0.8979, 0.8666, 0.8121, 0.9105, 0.9081, 0.9056,\n",
      "       0.8841, 0.781 , 0.7977, 0.8065, 0.7986, 0.8877]), 'std_test_score': array([0.00688404, 0.00458694, 0.00895935, 0.00451221, 0.01021567,\n",
      "       0.01335365, 0.00755976, 0.00793158, 0.01131503, 0.00689928,\n",
      "       0.00785111, 0.00368103, 0.0046422 , 0.00646838, 0.00384057,\n",
      "       0.0063561 , 0.00515655, 0.00695414, 0.00395348, 0.0093145 ,\n",
      "       0.00303809, 0.00357071, 0.00916679, 0.00594643, 0.00642106,\n",
      "       0.00852526, 0.00603573, 0.00692459, 0.00691954, 0.00281957]), 'rank_test_score': array([ 6, 23, 13,  4, 21, 30,  9, 14, 15, 22, 12, 15, 18,  5,  8, 19, 28,\n",
      "       17,  7, 20, 24,  1,  2,  3, 11, 29, 27, 25, 26, 10])}\n",
      "Total time elapsed: 4186\n"
     ]
    }
   ],
   "source": [
    "n_iter_search = 30 # número de configurações de parâmetros\n",
    "cv = 4 # cross validation samples\n",
    "njobs = 6\n",
    "\n",
    "grid_search = None\n",
    "if train_model and run_grid_search:\n",
    "    import time\n",
    "    print( time.strftime(\"%Y/%m/%d %H:%M:%S\", time.localtime() ) )\n",
    "    time_s_ = time.time()\n",
    "\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    #from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    param_distribs = {\n",
    "        \"base_estimator__max_depth\": np.arange(2,5),\n",
    "        \"base_estimator__min_samples_split\": np.arange(2,5),\n",
    "        \"n_estimators\": 100 * np.arange(2,6),\n",
    "        \"learning_rate\": 0.1 * np.arange(2,6)\n",
    "        }\n",
    "\n",
    "    grid_search = RandomizedSearchCV(\n",
    "        AdaBoostClassifier(\n",
    "            DecisionTreeClassifier(),\n",
    "            algorithm=\"SAMME.R\"\n",
    "            ),\n",
    "        param_distribs,\n",
    "        n_iter=n_iter_search, cv=cv, verbose=20, n_jobs=njobs, random_state=42\n",
    "        )\n",
    "    grid_search.fit( X_train_shuffle[:10000], y_train_shuffle[:10000] )\n",
    "\n",
    "    print ( grid_search.best_params_ )\n",
    "    print ( grid_search.best_score_ )\n",
    "    print ( grid_search.cv_results_ )\n",
    "    \n",
    "    time_e_ = time.time()\n",
    "    print ( \"Total time elapsed: {:.0f}\".format( time_e_ - time_s_ ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vOQ6v6d4cX4m"
   },
   "source": [
    "### Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YwhUerpQcWcW",
    "outputId": "71a047a8-3c9c-42da-91a0-1a18df353a61"
   },
   "outputs": [],
   "source": [
    "model_final = None\n",
    "\n",
    "if train_model:\n",
    "    max_depth_ = 4\n",
    "    min_samples_split_ = 3\n",
    "    n_estimators_ = 300\n",
    "    learning_rate_ = 0.3\n",
    "    if run_grid_search: \n",
    "#         model_final = grid_search.best_estimator_\n",
    "        params_ = grid_search.best_params_\n",
    "        max_depth_ = params_[ 'base_estimator__max_depth' ]\n",
    "        min_samples_split_ = params_[ 'base_estimator__min_samples_split' ]\n",
    "        n_estimators_ = params_[ 'n_estimators' ]\n",
    "        learning_rate_ = params_[ 'learning_rate' ]\n",
    "    \n",
    "    model_final = AdaBoostClassifier(\n",
    "            DecisionTreeClassifier(\n",
    "                max_depth=max_depth_,\n",
    "                min_samples_split=min_samples_split_\n",
    "            ),\n",
    "            n_estimators = n_estimators_,\n",
    "            algorithm=\"SAMME.R\",\n",
    "            learning_rate = learning_rate_\n",
    "            )\n",
    "    model_final.fit( X_train_shuffle, y_train_shuffle )\n",
    "else:\n",
    "    model_final = load( model_path )\n",
    " \n",
    "print ( model_final )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "leYy68aFc2iP"
   },
   "source": [
    "### Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EtC0pDOfc17M",
    "outputId": "6a49fe0c-f9d9-4024-dd3f-499525a60cd7"
   },
   "outputs": [],
   "source": [
    "y_predict_test = model_final.predict( X_test )\n",
    "\n",
    "accuracy = np.sum( y_predict_test == y_test ) / y_test.size\n",
    "print ( \"Accuracy = {}\".format( accuracy ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sQ6bTqstfr_D"
   },
   "outputs": [],
   "source": [
    "if train_model and save_model:\n",
    "#     dump( model_final, \"ada_clf.joblib\" )\n",
    "    dump( model_final, \"models/ada_clf.joblib\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3H7rOnPEWCwy",
    "outputId": "1adf649b-6698-49e2-e06d-81177444a359"
   },
   "outputs": [],
   "source": [
    "np.info( DecisionTreeClassifier )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP3vuA7k9I7j80no+5kUG/N",
   "include_colab_link": true,
   "name": "06-Classificação-Dígitos-BDT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
