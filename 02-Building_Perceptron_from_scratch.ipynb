{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UERJ-FISICA/ML4PPGF_UERJ/blob/PPGF-2023-2/02-Building_Perceptron_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7_r0qgqRgA3"
      },
      "source": [
        "## Taken from\n",
        "https://github.com/python-engineer/MLfromscratch/blob/master/mlfromscratch/perceptron.py\n",
        "\n",
        "In this notebook, we are going to build a neural network called the Perceptron using numpy and train it.\n",
        "\n",
        "## What is a neural network?\n",
        "A neural network is a type of machine learning model which is inspired by our neurons in the brain where many neurons are connected with many other neurons to translate an input to an output (simple right?). Mostly we can look at any machine learning model and think of it as a function which takes an input and produces the desired output; it's the same with a neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-hl9m_5RgA-"
      },
      "source": [
        "## What is a Perceptron?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irYCMIqKRgA_"
      },
      "source": [
        "The perceptron is an artificial neuron that constitutes the basic building block of many neural network architectures. Think of the perceptron as a function which takes a bunch of inputs multiply them with weights and add a bias term and activate this linear transformation with a nonlinearity to generate an output.\n",
        "\n",
        "<br/> <center>$Z= \\Theta( W \\cdot X + {b}) $</center> <br>\n",
        "\n",
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/aayushmnit/Deep_learning_explorations/master/1_MLP_from_scratch/perceptron.png\" align='center'> <br>\n",
        "<b>Fig 1: Perceptron</b>\n",
        "</center>\n",
        "\n",
        "\n",
        "$\\Theta$ is the Heaviside step function (the activation function in the Perceptron).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYMNL4ziRgBD"
      },
      "source": [
        "## Implementing the Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-06-03T19:03:20.951163-05:00",
          "start_time": "2018-06-03T19:03:20.941168Z"
        },
        "id": "r0uLZfmKRgBH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, learning_rate=0.01, n_iters=1000):\n",
        "        self.lr = learning_rate\n",
        "        self.n_iters = n_iters\n",
        "        self.activation_func = self._unit_step_func\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        # init parameters\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        y_ = np.array([1 if i > 0 else 0 for i in y])\n",
        "\n",
        "        for _ in range(self.n_iters):\n",
        "\n",
        "            for idx, x_i in enumerate(X):\n",
        "\n",
        "                linear_output = np.dot(x_i, self.weights) + self.bias\n",
        "                y_predicted = self.activation_func(linear_output)\n",
        "\n",
        "                # Perceptron update rule\n",
        "                update = self.lr * (y_[idx] - y_predicted)\n",
        "\n",
        "                self.weights += update * x_i\n",
        "                self.bias += update\n",
        "\n",
        "    def predict(self, X):\n",
        "        linear_output = np.dot(X, self.weights) + self.bias\n",
        "        y_predicted = self.activation_func(linear_output)\n",
        "        return y_predicted\n",
        "\n",
        "    def _unit_step_func(self, x):\n",
        "        return np.where(x >= 0, 1, 0)\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IE6ZRamERgBQ"
      },
      "source": [
        "##Training loop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "\n",
        "# Dataset\n",
        "X, y = datasets.make_blobs(\n",
        "    n_samples=150, n_features=2, centers=2, cluster_std=1.05, random_state=2\n",
        ")\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=123\n",
        ")\n",
        "\n",
        "print ( X_train.shape, X_train )\n",
        "print ( y_train.shape, y_train )\n",
        "\n",
        "def plot_data( X, y ):\n",
        "    plt.scatter( X[:, 0], X[:, 1], marker=\"o\", c=y)\n",
        "    plt.xlabel( r\"$x_1$\" )\n",
        "    plt.ylabel( r\"$x_2$\" )\n",
        "\n",
        "fig = plt.figure( figsize=(8,6) )\n",
        "plot_data( X_train, y_train )"
      ],
      "metadata": {
        "id": "afFY13mkz3U2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "p = Perceptron(learning_rate=0.01, n_iters=1000)\n",
        "p.fit(X_train, y_train)\n",
        "\n",
        "# Accuracy using test data set\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
        "    return accuracy\n",
        "\n",
        "predictions = p.predict(X_test)\n",
        "\n",
        "print(\"Perceptron classification accuracy:\", accuracy(y_test, predictions) )"
      ],
      "metadata": {
        "id": "DEI9kUIoozrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot results\n",
        "# Line that intercepts the y = 0 plane\n",
        "x1_1 = np.amin(X_train[:, 0])\n",
        "x1_2 = np.amax(X_train[:, 0])\n",
        "x2_1 = (-p.weights[0] * x1_1 - p.bias) / p.weights[1]\n",
        "x2_2 = (-p.weights[0] * x1_2 - p.bias) / p.weights[1]\n",
        "\n",
        "fig = plt.figure( figsize=(8,6) )\n",
        "plot_data( X_train, y_train )\n",
        "# plot_data( X_test, y_test )\n",
        "plt.plot( [x1_1, x1_2], [x2_1, x2_2], \"k\")\n",
        "x2_min = np.amin(X_train[:, 1])\n",
        "x2_max = np.amax(X_train[:, 1])\n",
        "plt.ylim([x2_min - 3, x2_max + 3])"
      ],
      "metadata": {
        "id": "jZyG4_fEqpyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eH5obp7HsDNs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "toc": {
      "colors": {
        "hover_highlight": "#DAA520",
        "navigate_num": "#000000",
        "navigate_text": "#333333",
        "running_highlight": "#FF0000",
        "selected_highlight": "#FFD700",
        "sidebar_border": "#EEEEEE",
        "wrapper_background": "#FFFFFF"
      },
      "moveMenuLeft": true,
      "nav_menu": {
        "height": "264px",
        "width": "252px"
      },
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 4,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false,
      "widenNotebook": false
    },
    "colab": {
      "name": "Building_Perceptron_from_scratch.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}